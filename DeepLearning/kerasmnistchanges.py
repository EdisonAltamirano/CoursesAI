# -*- coding: utf-8 -*-
"""kerasmnistchanges.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Df04LG6u5Cz_HD2lG90z7k3gZV3Pd-Tp

# Sensibilidad de Parametros en Redes Neuronales
"""

import keras
import numpy as np
from keras.datasets import mnist
import tensorflow as tf

(x_train,y_train),(x_test,y_test) = mnist.load_data()
x_train = x_train.reshape(x_train.shape[0],784)/255
x_test = x_test.reshape(x_test.shape[0],784)/255

y_train = keras.utils.np_utils.to_categorical(y_train,10)
y_test = keras.utils.np_utils.to_categorical(y_test,10)

"""## Red Neuronal Original"""

model = keras.Sequential(
  [
    keras.layers.Dense(10,input_dim=784,activation='sigmoid',name='layer1'),
    keras.layers.Dense(10,input_dim=128,activation='sigmoid',name='layer2'),
    keras.layers.Dense(10,input_dim=64,activation='sigmoid',name='layer3')
  ]
)

model.compile(loss='binary_crossentropy', optimizer="adam", metrics=["accuracy"])

model.fit(x_train, y_train, batch_size=128, epochs=15, validation_split=0.1)

score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

"""## Cambiando las Capas y Neuronas"""

model = keras.Sequential(
  [
    keras.layers.Dense(10,input_dim=512,input_shape=(784,),activation='sigmoid',name='layer2'),
    keras.layers.Dense(10,input_dim=512,input_shape=(784,),activation='sigmoid',name='layer3'),
  ]
)

model.compile(loss='binary_crossentropy', optimizer="adam", metrics=["accuracy"])

model.fit(x_train, y_train, batch_size=128, epochs=15, validation_split=0.1)

score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

"""## Gradient Descent"""

model = keras.Sequential(
  [
    keras.layers.Dense(10,input_dim=784,activation='sigmoid',name='layer1'),
    keras.layers.Dense(10,input_dim=128,activation='sigmoid',name='layer2'),
    keras.layers.Dense(10,input_dim=64,activation='sigmoid',name='layer3')
  ]
)

model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=1.0), metrics=["accuracy"])

model.fit(x_train, y_train, batch_size=128, epochs=15, validation_split=0.1)

score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

"""## Early Stopping"""

model = keras.Sequential(
  [
    keras.layers.Dense(10,input_dim=784,activation='sigmoid',name='layer1'),
    keras.layers.Dense(10,input_dim=128,activation='sigmoid',name='layer2'),
    keras.layers.Dense(10,input_dim=64,activation='sigmoid',name='layer3')
  ]
)

model.compile(loss='binary_crossentropy', optimizer="adam", metrics=["accuracy"])
es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1)
model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15, verbose=0, callbacks=[es])

score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

"""## Dropout"""

model = keras.Sequential()
model.add(keras.layers.Dense(10,input_dim=784,activation='sigmoid',name='layer1'))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.Dense(10,input_dim=128,activation='sigmoid',name='layer2'))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.Dense(10,input_dim=64,activation='sigmoid',name='layer3'))

model.compile(loss='binary_crossentropy', optimizer="adam", metrics=["accuracy"])

model.fit(x_train, y_train, batch_size=128, epochs=15, validation_split=0.1)

score = model.evaluate(x_test, y_test, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])