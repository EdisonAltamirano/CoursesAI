{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>39</th>\n",
       "      <th>State-gov</th>\n",
       "      <th>77516</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>13</th>\n",
       "      <th>Never-married</th>\n",
       "      <th>Adm-clerical</th>\n",
       "      <th>Not-in-family</th>\n",
       "      <th>White</th>\n",
       "      <th>Male</th>\n",
       "      <th>2174</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <th>&lt;=50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   39          State-gov   77516   Bachelors   13        Never-married  \\\n",
       "0  50   Self-emp-not-inc   83311   Bachelors   13   Married-civ-spouse   \n",
       "1  38            Private  215646     HS-grad    9             Divorced   \n",
       "2  53            Private  234721        11th    7   Married-civ-spouse   \n",
       "3  28            Private  338409   Bachelors   13   Married-civ-spouse   \n",
       "4  37            Private  284582     Masters   14   Married-civ-spouse   \n",
       "\n",
       "         Adm-clerical   Not-in-family   White     Male   2174   0   40  \\\n",
       "0     Exec-managerial         Husband   White     Male      0   0   13   \n",
       "1   Handlers-cleaners   Not-in-family   White     Male      0   0   40   \n",
       "2   Handlers-cleaners         Husband   Black     Male      0   0   40   \n",
       "3      Prof-specialty            Wife   Black   Female      0   0   40   \n",
       "4     Exec-managerial            Wife   White   Female      0   0   40   \n",
       "\n",
       "    United-States   <=50K  \n",
       "0   United-States   <=50K  \n",
       "1   United-States   <=50K  \n",
       "2   United-States   <=50K  \n",
       "3            Cuba   <=50K  \n",
       "4   United-States   <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naives_bayes=MultinomialNB()\n",
    "decision_tree=DecisionTreeClassifier()\n",
    "folds=[2,4,6,8,10,12,14,16]\n",
    "splits=[0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55]\n",
    "seed=6896#random.randint(0, 10000)\n",
    "data=\"adult.data\"\n",
    "df = pd.read_csv(data)\n",
    "#df.info()\n",
    "#df.describe()\n",
    "#print(df.head())\n",
    "#print(df[['<=50K']].value_counts())\n",
    "df.head()\n",
    "# a = df.iloc[:,14]\n",
    "# count=0\n",
    "# count1=0\n",
    "\n",
    "# for i in a:\n",
    "#     if i==\" <=50K\":\n",
    "#         count1+=1\n",
    "#     #if i=='<=50K':\n",
    "#     count+=1\n",
    "\n",
    "# print(count-(count1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' Without-pay': 0, ' Never-worked': 1, ' State-gov': 2, ' Self-emp-not-inc': 3, ' Self-emp-inc': 4, ' Local-gov': 5, ' Private': 6, ' ?': 32, ' Federal-gov': 8, ' 10th': 0, ' Doctorate': 1, ' 11th': 2, ' Assoc-voc': 3, ' Preschool': 4, ' Assoc-acdm': 5, ' 5th-6th': 6, ' Prof-school': 7, ' 9th': 8, ' Some-college': 9, ' 7th-8th': 10, ' 1st-4th': 11, ' 12th': 12, ' HS-grad': 13, ' Bachelors': 14, ' Masters': 15, ' Married-civ-spouse': 0, ' Married-spouse-absent': 1, ' Never-married': 2, ' Divorced': 3, ' Widowed': 4, ' Separated': 5, ' Married-AF-spouse': 6, ' Transport-moving': 0, ' Craft-repair': 1, ' Machine-op-inspct': 2, ' Other-service': 3, ' Tech-support': 4, ' Armed-Forces': 5, ' Handlers-cleaners': 7, ' Priv-house-serv': 8, ' Farming-fishing': 9, ' Sales': 10, ' Protective-serv': 11, ' Prof-specialty': 12, ' Exec-managerial': 13, ' Adm-clerical': 14, ' Not-in-family': 0, ' Own-child': 1, ' Wife': 2, ' Unmarried': 3, ' Husband': 4, ' Other-relative': 5, ' White': 0, ' Black': 1, ' Other': 2, ' Asian-Pac-Islander': 3, ' Amer-Indian-Eskimo': 4, ' Male': 0, ' Female': 1, ' Guatemala': 0, ' Canada': 1, ' United-States': 2, ' Columbia': 3, ' Cambodia': 4, ' Cuba': 5, ' Taiwan': 6, ' El-Salvador': 7, ' Yugoslavia': 8, ' Germany': 9, ' Vietnam': 10, ' Nicaragua': 11, ' Portugal': 12, ' Japan': 13, ' Laos': 14, ' India': 15, ' Philippines': 16, ' South': 17, ' Poland': 18, ' Outlying-US(Guam-USVI-etc)': 19, ' Jamaica': 20, ' China': 21, ' Honduras': 22, ' Peru': 23, ' Scotland': 24, ' Dominican-Republic': 25, ' Greece': 26, ' Ireland': 27, ' Hungary': 28, ' Hong': 29, ' Trinadad&Tobago': 30, ' Italy': 31, ' Holand-Netherlands': 33, ' France': 34, ' Ecuador': 35, ' Haiti': 36, ' England': 37, ' Iran': 38, ' Mexico': 39, ' Thailand': 40, ' Puerto-Rico': 41, ' >50K': 0, ' <=50K': 1}\n"
     ]
    }
   ],
   "source": [
    "replace_dict={}\n",
    "for index,j in enumerate(df):\n",
    "    count =0\n",
    "    for i in set(df.iloc[:, index]):\n",
    "        if(type(i)==str):\n",
    "            replace_dict[i]=count\n",
    "            count+=1\n",
    "print(replace_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>39</th>\n",
       "      <th>State-gov</th>\n",
       "      <th>77516</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>13</th>\n",
       "      <th>Never-married</th>\n",
       "      <th>Adm-clerical</th>\n",
       "      <th>Not-in-family</th>\n",
       "      <th>White</th>\n",
       "      <th>Male</th>\n",
       "      <th>2174</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>83311</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>215646</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>234721</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>338409</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>284582</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   39   State-gov   77516   Bachelors   13   Never-married   Adm-clerical  \\\n",
       "0  50           3   83311          14   13               0             13   \n",
       "1  38           6  215646          13    9               3              7   \n",
       "2  53           6  234721           2    7               0              7   \n",
       "3  28           6  338409          14   13               0             12   \n",
       "4  37           6  284582          15   14               0             13   \n",
       "\n",
       "    Not-in-family   White   Male   2174   0   40   United-States  \n",
       "0               4       0      0      0   0   13               2  \n",
       "1               0       0      0      0   0   40               2  \n",
       "2               4       1      0      0   0   40               2  \n",
       "3               2       1      1      0   0   40               5  \n",
       "4               2       0      1      0   0   40               2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df.iloc[:, -1]\n",
    "numeric_df = df.iloc[:,:-1].replace(replace_dict)\n",
    "columns = df.columns.array[:-1]\n",
    "class_values = set(classes)\n",
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classification_report_csv(report,mydata):\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        if len(row_data)==6:\n",
    "            row['class'] = row_data[1]\n",
    "            row['precision'] = row_data[2]\n",
    "            row['recall'] = row_data[3]\n",
    "            row['f1_score'] = row_data[4]\n",
    "            row['support'] = row_data[5]\n",
    "            mydata.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_evaluation(model, test_data, test_classes, class_values):\n",
    "    predictions = model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_classes, predictions)\n",
    "    print(\"Accuracy score: \",accuracy)\n",
    "    confusion_mat = confusion_matrix(test_classes, predictions)\n",
    "    print(confusion_mat)\n",
    "    report = classification_report(test_classes, predictions, target_names=class_values, zero_division=0)\n",
    "    print(report)\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba 1\n",
      "Training data: 80.0    Test data: 20.0\n",
      "Decision tree report\n",
      "Accuracy score:  0.8138820638820639\n",
      "[[4299  639]\n",
      " [ 573 1001]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.88      4938\n",
      "       <=50K       0.61      0.64      0.62      1574\n",
      "\n",
      "    accuracy                           0.81      6512\n",
      "   macro avg       0.75      0.75      0.75      6512\n",
      "weighted avg       0.82      0.81      0.82      6512\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.785012285012285\n",
      "[[4723  215]\n",
      " [1185  389]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      4938\n",
      "       <=50K       0.64      0.25      0.36      1574\n",
      "\n",
      "    accuracy                           0.79      6512\n",
      "   macro avg       0.72      0.60      0.61      6512\n",
      "weighted avg       0.76      0.79      0.75      6512\n",
      "\n",
      "Prueba 2\n",
      "Training data: 75.0    Test data: 25.0\n",
      "Decision tree report\n",
      "Accuracy score:  0.8115479115479115\n",
      "[[5333  827]\n",
      " [ 707 1273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.87      6160\n",
      "       <=50K       0.61      0.64      0.62      1980\n",
      "\n",
      "    accuracy                           0.81      8140\n",
      "   macro avg       0.74      0.75      0.75      8140\n",
      "weighted avg       0.82      0.81      0.81      8140\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7862407862407862\n",
      "[[5888  272]\n",
      " [1468  512]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      6160\n",
      "       <=50K       0.65      0.26      0.37      1980\n",
      "\n",
      "    accuracy                           0.79      8140\n",
      "   macro avg       0.73      0.61      0.62      8140\n",
      "weighted avg       0.76      0.79      0.75      8140\n",
      "\n",
      "Prueba 3\n",
      "Training data: 70.0    Test data: 30.0\n",
      "Decision tree report\n",
      "Accuracy score:  0.8093775593775594\n",
      "[[6397  988]\n",
      " [ 874 1509]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.87      7385\n",
      "       <=50K       0.60      0.63      0.62      2383\n",
      "\n",
      "    accuracy                           0.81      9768\n",
      "   macro avg       0.74      0.75      0.75      9768\n",
      "weighted avg       0.81      0.81      0.81      9768\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7856265356265356\n",
      "[[7067  318]\n",
      " [1776  607]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      7385\n",
      "       <=50K       0.66      0.25      0.37      2383\n",
      "\n",
      "    accuracy                           0.79      9768\n",
      "   macro avg       0.73      0.61      0.62      9768\n",
      "weighted avg       0.76      0.79      0.75      9768\n",
      "\n",
      "Prueba 4\n",
      "Training data: 65.0    Test data: 35.0\n",
      "Decision tree report\n",
      "Accuracy score:  0.8173920673920674\n",
      "[[7523 1124]\n",
      " [ 957 1792]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.89      0.87      0.88      8647\n",
      "       <=50K       0.61      0.65      0.63      2749\n",
      "\n",
      "    accuracy                           0.82     11396\n",
      "   macro avg       0.75      0.76      0.76     11396\n",
      "weighted avg       0.82      0.82      0.82     11396\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.788083538083538\n",
      "[[8285  362]\n",
      " [2053  696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      8647\n",
      "       <=50K       0.66      0.25      0.37      2749\n",
      "\n",
      "    accuracy                           0.79     11396\n",
      "   macro avg       0.73      0.61      0.62     11396\n",
      "weighted avg       0.77      0.79      0.75     11396\n",
      "\n",
      "Prueba 5\n",
      "Training data: 60.0    Test data: 40.0\n",
      "Decision tree report\n",
      "Accuracy score:  0.8126535626535627\n",
      "[[8613 1255]\n",
      " [1185 1971]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.88      9868\n",
      "       <=50K       0.61      0.62      0.62      3156\n",
      "\n",
      "    accuracy                           0.81     13024\n",
      "   macro avg       0.75      0.75      0.75     13024\n",
      "weighted avg       0.81      0.81      0.81     13024\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7870853808353808\n",
      "[[9474  394]\n",
      " [2379  777]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      9868\n",
      "       <=50K       0.66      0.25      0.36      3156\n",
      "\n",
      "    accuracy                           0.79     13024\n",
      "   macro avg       0.73      0.60      0.62     13024\n",
      "weighted avg       0.77      0.79      0.75     13024\n",
      "\n",
      "Prueba 6\n",
      "Training data: 55.00000000000001    Test data: 45.0\n",
      "Decision tree report\n",
      "Accuracy score:  0.8093093093093093\n",
      "[[9642 1437]\n",
      " [1357 2216]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.87     11079\n",
      "       <=50K       0.61      0.62      0.61      3573\n",
      "\n",
      "    accuracy                           0.81     14652\n",
      "   macro avg       0.74      0.75      0.74     14652\n",
      "weighted avg       0.81      0.81      0.81     14652\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7842615342615342\n",
      "[[10634   445]\n",
      " [ 2716   857]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87     11079\n",
      "       <=50K       0.66      0.24      0.35      3573\n",
      "\n",
      "    accuracy                           0.78     14652\n",
      "   macro avg       0.73      0.60      0.61     14652\n",
      "weighted avg       0.76      0.78      0.74     14652\n",
      "\n",
      "Prueba 7\n",
      "Training data: 50.0    Test data: 50.0\n",
      "Decision tree report\n",
      "Accuracy score:  0.8105036855036855\n",
      "[[10723  1566]\n",
      " [ 1519  2472]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.87     12289\n",
      "       <=50K       0.61      0.62      0.62      3991\n",
      "\n",
      "    accuracy                           0.81     16280\n",
      "   macro avg       0.74      0.75      0.75     16280\n",
      "weighted avg       0.81      0.81      0.81     16280\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7828009828009828\n",
      "[[11787   502]\n",
      " [ 3034   957]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87     12289\n",
      "       <=50K       0.66      0.24      0.35      3991\n",
      "\n",
      "    accuracy                           0.78     16280\n",
      "   macro avg       0.73      0.60      0.61     16280\n",
      "weighted avg       0.76      0.78      0.74     16280\n",
      "\n",
      "Prueba 8\n",
      "Training data: 44.99999999999999    Test data: 55.00000000000001\n",
      "Decision tree report\n",
      "Accuracy score:  0.8109224927406745\n",
      "[[11783  1770]\n",
      " [ 1616  2739]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.87     13553\n",
      "       <=50K       0.61      0.63      0.62      4355\n",
      "\n",
      "    accuracy                           0.81     17908\n",
      "   macro avg       0.74      0.75      0.75     17908\n",
      "weighted avg       0.81      0.81      0.81     17908\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7845655572928301\n",
      "[[12981   572]\n",
      " [ 3286  1069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87     13553\n",
      "       <=50K       0.65      0.25      0.36      4355\n",
      "\n",
      "    accuracy                           0.78     17908\n",
      "   macro avg       0.72      0.60      0.61     17908\n",
      "weighted avg       0.76      0.78      0.75     17908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_id = 1\n",
    "decision_report=[]\n",
    "naives_report=[]\n",
    "for split_ratio in splits:\n",
    "    (training_data, test_data, training_classes, test_classes) = train_test_split(\n",
    "        numeric_df,\n",
    "        classes,\n",
    "        test_size=split_ratio,\n",
    "        random_state=seed\n",
    "    )\n",
    "    print(f\"Prueba {test_id}\")\n",
    "    print(f\"Training data: {(1 - split_ratio) * 100}    Test data: {(split_ratio * 100)}\")\n",
    "    naive_bayes_model = naives_bayes.fit(training_data, training_classes)\n",
    "    decision_tree_model = decision_tree.fit(training_data, training_classes) \n",
    "    print(\"Decision tree report\")\n",
    "    tree_text = export_text(decision_tree_model, feature_names=columns)\n",
    "    #print(tree_text)\n",
    "    decision_report1 = print_model_evaluation(decision_tree_model, test_data, test_classes, class_values)\n",
    "    decision_report2=classification_report_csv(decision_report1,decision_report)\n",
    "    print(\"Naive Bayes report\")\n",
    "    naives_report1=print_model_evaluation(naive_bayes_model, test_data, test_classes, class_values)\n",
    "    naives_report2=classification_report_csv(naives_report1,naives_report)\n",
    "\n",
    "    test_id += 1\n",
    "dataframe = pd.DataFrame.from_dict(naives_report)\n",
    "dataframe.to_csv('naives_report.csv', index = False)\n",
    "dataframe = pd.DataFrame.from_dict(decision_report)\n",
    "dataframe.to_csv('decision_report.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_splitted_data(data, classes, fold):\n",
    "    skf = StratifiedKFold(fold, shuffle=False)\n",
    "    for train_index, test_index in skf.split(data, classes):\n",
    "        training_data, test_data = data.iloc[train_index], data.iloc[test_index]\n",
    "        training_classes, test_classes = classes[train_index], classes[test_index]\n",
    "    return (training_data, test_data, training_classes, test_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruebas 1 \n",
      "Folds: 2\n",
      "Decision tree report\n",
      "Accuracy score:  0.8135749385749386\n",
      "[[10798  1561]\n",
      " [ 1474  2447]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.88     12359\n",
      "       <=50K       0.61      0.62      0.62      3921\n",
      "\n",
      "    accuracy                           0.81     16280\n",
      "   macro avg       0.75      0.75      0.75     16280\n",
      "weighted avg       0.82      0.81      0.81     16280\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7843366093366093\n",
      "[[11811   548]\n",
      " [ 2963   958]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87     12359\n",
      "       <=50K       0.64      0.24      0.35      3921\n",
      "\n",
      "    accuracy                           0.78     16280\n",
      "   macro avg       0.72      0.60      0.61     16280\n",
      "weighted avg       0.76      0.78      0.75     16280\n",
      "\n",
      "Pruebas 2 \n",
      "Folds: 4\n",
      "Decision tree report\n",
      "Accuracy score:  0.8141277641277641\n",
      "[[5404  775]\n",
      " [ 738 1223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.88      6179\n",
      "       <=50K       0.61      0.62      0.62      1961\n",
      "\n",
      "    accuracy                           0.81      8140\n",
      "   macro avg       0.75      0.75      0.75      8140\n",
      "weighted avg       0.82      0.81      0.81      8140\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7861179361179361\n",
      "[[5918  261]\n",
      " [1480  481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      6179\n",
      "       <=50K       0.65      0.25      0.36      1961\n",
      "\n",
      "    accuracy                           0.79      8140\n",
      "   macro avg       0.72      0.60      0.61      8140\n",
      "weighted avg       0.76      0.79      0.75      8140\n",
      "\n",
      "Pruebas 3 \n",
      "Folds: 6\n",
      "Decision tree report\n",
      "Accuracy score:  0.8103575377810542\n",
      "[[3585  534]\n",
      " [ 495  812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.87      4119\n",
      "       <=50K       0.60      0.62      0.61      1307\n",
      "\n",
      "    accuracy                           0.81      5426\n",
      "   macro avg       0.74      0.75      0.74      5426\n",
      "weighted avg       0.81      0.81      0.81      5426\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7895318835237745\n",
      "[[3956  163]\n",
      " [ 979  328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      4119\n",
      "       <=50K       0.67      0.25      0.36      1307\n",
      "\n",
      "    accuracy                           0.79      5426\n",
      "   macro avg       0.73      0.61      0.62      5426\n",
      "weighted avg       0.77      0.79      0.75      5426\n",
      "\n",
      "Pruebas 4 \n",
      "Folds: 8\n",
      "Decision tree report\n",
      "Accuracy score:  0.8125307125307125\n",
      "[[2698  391]\n",
      " [ 372  609]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.88      3089\n",
      "       <=50K       0.61      0.62      0.61       981\n",
      "\n",
      "    accuracy                           0.81      4070\n",
      "   macro avg       0.74      0.75      0.75      4070\n",
      "weighted avg       0.81      0.81      0.81      4070\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7884520884520885\n",
      "[[2967  122]\n",
      " [ 739  242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      3089\n",
      "       <=50K       0.66      0.25      0.36       981\n",
      "\n",
      "    accuracy                           0.79      4070\n",
      "   macro avg       0.73      0.60      0.62      4070\n",
      "weighted avg       0.77      0.79      0.75      4070\n",
      "\n",
      "Pruebas 5 \n",
      "Folds: 10\n",
      "Decision tree report\n",
      "Accuracy score:  0.812960687960688\n",
      "[[2149  322]\n",
      " [ 287  498]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.88      2471\n",
      "       <=50K       0.61      0.63      0.62       785\n",
      "\n",
      "    accuracy                           0.81      3256\n",
      "   macro avg       0.74      0.75      0.75      3256\n",
      "weighted avg       0.82      0.81      0.81      3256\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7917690417690417\n",
      "[[2380   91]\n",
      " [ 587  198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.88      2471\n",
      "       <=50K       0.69      0.25      0.37       785\n",
      "\n",
      "    accuracy                           0.79      3256\n",
      "   macro avg       0.74      0.61      0.62      3256\n",
      "weighted avg       0.77      0.79      0.75      3256\n",
      "\n",
      "Pruebas 6 \n",
      "Folds: 12\n",
      "Decision tree report\n",
      "Accuracy score:  0.8105418356063399\n",
      "[[1778  281]\n",
      " [ 233  421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.86      0.87      2059\n",
      "       <=50K       0.60      0.64      0.62       654\n",
      "\n",
      "    accuracy                           0.81      2713\n",
      "   macro avg       0.74      0.75      0.75      2713\n",
      "weighted avg       0.82      0.81      0.81      2713\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7895318835237745\n",
      "[[1984   75]\n",
      " [ 496  158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      2059\n",
      "       <=50K       0.68      0.24      0.36       654\n",
      "\n",
      "    accuracy                           0.79      2713\n",
      "   macro avg       0.74      0.60      0.62      2713\n",
      "weighted avg       0.77      0.79      0.75      2713\n",
      "\n",
      "Pruebas 7 \n",
      "Folds: 14\n",
      "Decision tree report\n",
      "Accuracy score:  0.8055913978494623\n",
      "[[1521  244]\n",
      " [ 208  352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.86      0.87      1765\n",
      "       <=50K       0.59      0.63      0.61       560\n",
      "\n",
      "    accuracy                           0.81      2325\n",
      "   macro avg       0.74      0.75      0.74      2325\n",
      "weighted avg       0.81      0.81      0.81      2325\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7870967741935484\n",
      "[[1699   66]\n",
      " [ 429  131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      1765\n",
      "       <=50K       0.66      0.23      0.35       560\n",
      "\n",
      "    accuracy                           0.79      2325\n",
      "   macro avg       0.73      0.60      0.61      2325\n",
      "weighted avg       0.77      0.79      0.75      2325\n",
      "\n",
      "Pruebas 8 \n",
      "Folds: 16\n",
      "Decision tree report\n",
      "Accuracy score:  0.8127764127764128\n",
      "[[1337  207]\n",
      " [ 174  317]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.88      0.87      0.88      1544\n",
      "       <=50K       0.60      0.65      0.62       491\n",
      "\n",
      "    accuracy                           0.81      2035\n",
      "   macro avg       0.74      0.76      0.75      2035\n",
      "weighted avg       0.82      0.81      0.81      2035\n",
      "\n",
      "Naive Bayes report\n",
      "Accuracy score:  0.7877149877149877\n",
      "[[1488   56]\n",
      " [ 376  115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        >50K       0.80      0.96      0.87      1544\n",
      "       <=50K       0.67      0.23      0.35       491\n",
      "\n",
      "    accuracy                           0.79      2035\n",
      "   macro avg       0.74      0.60      0.61      2035\n",
      "weighted avg       0.77      0.79      0.75      2035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_id = 1\n",
    "decision_report=[]\n",
    "naives_report=[]\n",
    "for fold in folds:\n",
    "    (training_data, test_data, training_classes, test_classes) = get_fold_splitted_data(numeric_df, classes, fold)\n",
    "    print(f\"Pruebas {test_id} \")\n",
    "    print(\"Folds: \" + str(fold))\n",
    "    naive_bayes_model = naives_bayes.fit(training_data, training_classes)\n",
    "    decision_tree_model = decision_tree.fit(training_data, training_classes) \n",
    "    print(\"Decision tree report\")\n",
    "    tree_text = export_text(decision_tree_model, feature_names=columns)\n",
    "    #print(tree_text)\n",
    "    decision_report1 = print_model_evaluation(decision_tree_model, test_data, test_classes, class_values)\n",
    "    decision_report2=classification_report_csv(decision_report1,decision_report)\n",
    "    print(\"Naive Bayes report\")\n",
    "    naives_report1=print_model_evaluation(naive_bayes_model, test_data, test_classes, class_values)\n",
    "    naives_report2=classification_report_csv(naives_report1,naives_report)\n",
    "    test_id += 1\n",
    "dataframe = pd.DataFrame.from_dict(naives_report)\n",
    "dataframe.to_csv('naives_report1.csv', index = False)\n",
    "dataframe = pd.DataFrame.from_dict(decision_report)\n",
    "dataframe.to_csv('decision_report1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlations\n",
    "correlations = numeric_df.corr()\n",
    "\n",
    "# plot the heatmap \n",
    "sns.heatmap(correlations, xticklabels=correlations.columns, yticklabels=classes, annot=True)\n",
    "\n",
    "# plot the clustermap \n",
    "sns.clustermap(correlations, xticklabels=correlations.columns, yticklabels=classes, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52621260eea9cf383bf1246807ee6bb921277aa871fba976eff6c1457246b2de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
